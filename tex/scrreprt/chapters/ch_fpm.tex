% !TEX root = ../ba_scrreprt_master.tex
% @author Marcel Ruland (2018)

\chapter{Applying \fpmupper}
\label{ch:mining}
\chapterintro{chapter description goes here}

\section{Method}
\label{sec:miningmethod}
The following subsections begin by introducing the raw data \emph{as-is} and then proceed by describing the process of annotating and evaluating the data, thus going steadily from the most concrete to more and more abstract representations. I begin by describing the contents of the video corpus and eventually end with abstract rules\footnote{For the definition of \emph{rule} here, see subsection \ref{ssec:miningmethodapproach}.}.

\subsection{The Nature of the Data}
\label{ssec:miningmethodnature}
The corpus is a collection of 10 mother--infant dyads. Infants were 3 months of age, mothers between 28 and 40 years. Mother and infant were recorded at their own homes during a diaper routine. This routine was chosen because it a)~is an activity familiar to both mother and infant, b)~is an activity where mother and infant are in direct communication with each other for a relatively long period of time, c)~both mother and infant are free in their expressions. The infant especially is free to make use of body movements and gestures and is not reliant on support from the mother, as might be the case if the infant were sitting. The diaper routine was recorded by two video cameras from two different perspectives, such that all relevant events were clearly visible. Figure \ref{fig:rawvid} gives an impression of this raw data. For a more detailed description of the setup see \citet[\snum{2.1}]{nomikou17} and \citet[\pnum{115~f.}]{nomikou11}.\footnote{But note that while the same setup was used, the inclusion or exclusion of groups or individual subjects in the corpus was different due to the different aims of the studies.} The videos had a mean length of 395~s (\emph{\textsc{sd}}~=~186~s).

\begin{figure}[h]
	\centering
	\includegraphics[width=\imgwidth]{../aux/img/video_vp_08_raw.png}
	\label{fig:rawvid}
	\caption{Screen capture of the raw video data}
\end{figure}

\subsection{Annotation of the Videos}
\label{ssec:miningmethodannotation}
11 kinds of events were hand-coded frame per frame for both mother and child using the \textsc{elan} software \citep{wittenburg06}, yielding an accuracy of \textasciitilde40~ms (videos were recorded with 25 frames per second, resulting in a single frame being 40~ms long). These events were of linguistic, vocal, and visual modality. %Categories were chosen how? Elaborate here.
Table \ref{tab:events} lists all categories. Every annotation contains a start and end time point and therefore also the duration of the respective event. For example, one specific annotation might say that the mother started smiling at 32.645~seconds and then smiled continuously until 36.765~seconds, where she stopped smiling again. This way, sequences as schematised in Figure \ref{fig:idealseq} are obtained. \fpmlabel{A}, \fpmlabel{B}, and \fpmlabel{C} are three different kinds of events; the x-axis represents time. We see two occurrences of type \fpmlabel{A} and \fpmlabel{B} each, as well as a longer occurrence of type \fpmlabel{C}. Those time points that are indicated on the x-axis mark the beginning and/or end time point of a specific occurrence.

\begin{table}[h]
	\centering
	\begin{tabularx}{\textwidth}{>{\ttfamily}lX} 
		\toprule
		{\rmfamily Event}		& Explanation \\
		\cmidrule(lr){1-1} \cmidrule(lr){2-2}
		mother\_speech			& mother speaks \\
		mother\_vocal			& mother vocalises, but does not use language \\
		mother\_gaze\_infant	& mother gazes at infant \\
		mother\_gaze\_object	& mother gazing at object, usually diaper but may be any object \\
		mother\_gaze\_away		& mother gazes neither at infant nor at object \\
		mother\_smile			& mother smiles \\
		\cmidrule(lr){1-1} \cmidrule(lr){2-2}
		infant\_vocal \\
		infant\_gaze\_mother \\
		i\_gaze\_object			& ~ \hfill \textit{analogous to mother's events} \hfill ~ \\
		i\_gaze\_away \\
		infant\_smile \\
		\bottomrule
	\end{tabularx}
	\caption{Events coded in the data}
	\label{tab:events}
\end{table}

\paragraph{A note on terminology}
%A mother--infant pair is referred to as a \emph{dyad.}
One individual occurrence of an event is simply referred to as an \emph{event} (the mother's smile described as an example in the previous paragraph is an event).
A specific kind of event is referred to as a \emph{dimension} (the example event is of dimension \code{mother\_smile}; the whole dimension \code{mother\_smile} is the totality of all events of this type; as there are 11 kinds of events, the data are 11-dimensional).
All events obtained from annotating the recording of a single mother--infant dyad are referred to as a \emph{sequence.}
Finally, all 10 sequences together are referred to as the \emph{corpus.}

\begin{figure}
	\centering
	\input{../aux/tikzpictures/tikz_idealseq.tex}
	\caption{Graphical representation of sequence structure}
	\label{fig:idealseq}
\end{figure}

\subsection{Mining Approach}
\label{ssec:miningmethodapproach}

\paragraph{Association Rules}
The patterns \citet{rohlfing18} mined were association rules of the form \fpmrule{A}{B}, where the probability of the succedent \fpmset{B} was high given the antecedent \fpmset{A}. Note that antecedent and succedent are not single events but sets of events. One may equally well form a hypothetical rule of the form \fpmrule{B,D}{A,C,D}. Occurrences of a rule were taken into account if the antecedent's end time point lay before the succedent's start time point \emph{and} one of the following two conditions was fulfilled:

\begin{enumerate}
	\item The antecedent's start time point lies before that of the succedent.
	\item The antecedent's and succedent's start time points are identical, i.e.\ they begin at the same time.
\end{enumerate}

Referring again to Figure \ref{fig:idealseq}, one can for example observe the rules \fpmrule{A}{B} and \fpmrule{A}{B,C} (because the start time point of the antecedent lies before that of the succedent), but not \fpmrule{B}{A}.

\paragraph{Adapting the mining scheme}
This scheme can be further adapted to the specific nature of the data. Given that the data are hand-coded and that time points are stored with a precision up tp 1~ms, the second condition will in all probability never be true. Regarding the first condition, the natural imprecision of coding by hand can lead to one annotation beginning before or after another essentially by pure chance, when in fact the two events begin at the same time. The notion of \emph{at the same time} itself is problematic as well. Humans exhibit a certain reaction time to stimuli, which is always greater than 0~ms. It logically follows that if both mother and infant begin exhibiting a certain event \emph{at the same time,} then one event cannot be a reaction to the other because such a reaction would demand an appropriate reaction time. Therefore, an interpersonal rule where both events begin at the same time is the result of pure chance. Not only will it be a meaningless rule, but also an incorrect rule and\dash accordingly\dash should not be captured as a rule at all.

\paragraph{Choosing appropriate delays}  % Clarify this entire paragraph, content is good but confusingly written. Also have a look at the huge ass turn-taking reader for more literature on \rt\ in communication/interaction
Human reaction time (henceforth \rt) correlates with a vast variety of factors, among which are intensity, modality, and complexity of the stimulus \citep{brebner80}, age and gender \citep{der06}, state of alertness \citep{appelle74}, handedness \citep{dane03}, and even personality traits \citep{stelmack93}. Quite obviously, many of those traits cannot be determined for the subjects in the corpus used in the present thesis. However, those factors which are most relevant (namely age of the subject and modality of the stimulus) are both captured in the data and relatively easy to account for. Regarding modality, variation is very small. \citet[\pnum{9}]{brebner80} ascribe variation to ``differences in the peripheral mechanisms rather than in the central processes'' and give average\footnote{I use the term \emph{average} wherever sources do not state whether the value in question is a mean, median, mode, or other measure of centrality.} \rt s of 8--10~ms for acoustic stimuli and 20--40~ms for visual stimuli to reach the central processes. The resulting difference of 10--32~ms may of course be incorporated in a model of \rt s in the corpus used here, but modelling different \rt s depending on the kind of stimulus complicates the algorithm considerably. For practical reasons, I have therefore decided to not include the modality of the stimulus for now. Regarding age, mean \rt\ lies  between 1002--1124~ms for infants of age 6--9 months (N~=~24) and between 311--326~ms for adults of age 19--26 years (N=11) \citep[\pnum{95}]{leibold02}.%
\footnote{Stimulus was a pure (i.e.~sine wave) tone of 1000~Hz with loudness ranging from 40--60~dB. No numerical values given. Converted from line chart using the Engauge Digitizer software \citep{mitchell02}. The loudness corresponds to average loudness perceived in conversation \citep[\pnum{32}]{goerne06}} It would obviously have been desirable to have \rt\ values of 3 month old infants, given that the infants in the  corpus used in the present thesis are 3 months of age. Unfortunately, such literature does not seem to be available, so the age difference of 3--6 months cannot be avoided for now. Neverthelss, the important point made is that there \emph{is} a considerable difference in reaction time between infants and adults that must be taken into account. In my analysis, I therefore capture rules of the sort \fpmtextrule{infant}{mother} (i.e.~mother has to react) if and only if the delay between the start time point of the antecedent is greater than 289~ms before that of the succedent. Similarly, rules of the sort \fpmtextrule{mother}{infant} (i.e.~infant has to react) are captured if and only if the delay between the start time point of the antecedent is greater than 850~ms before that of the succedent. The values are those given by \citet{leibold02} minus two standard deviations. This way\dash assuming \rt s to be normally distributed\dash 97.5~\% of \rt s will be longer than the given delays \citep[\pnum{57}]{moore16}. Consequently, only 2.5~\% of \rt s will falsely be sorted out as coincidence.

\paragraph{Reaction time in interaction}
I am well aware that the literature cited with regards to the delays chosen is concerned with \rt\ to general stimuli and does not consider communication or interaction specifically. Unfortunately, literature specifically concerned with \rt\ in interaction is virtually inexistent. There are some indications that it may be faster than general \rt\ \citep{levinson16}, but none that it may be slower. \citepos{levinson16} argument deserves further attention. It unpacks as follows:

Turn-taking is not a cultural phenomenon but a universal feature of human language. The fastest \rt\ humans are capable of is around 200~ms. This is the \rt\ to a simple start signal with only one possible reaction. According to Hick's law \citep{hick52}, human \rt\ increases logarithmically with the number of available response choices. Taking vocabulary alone into consideration, languages offer at least 50000 response choices, so that one would expect \rt\ in language to be far above said 200~ms. Furthermore, the production of a single primed word takes around 600~ms, short clauses can take around 1500~ms. Despite all this, the modal gap between turns is also around 200~ms. It follows logically, that production planning must begin before the end of the previous turn. I have schematised this process on the left side of figure \ref{fig:levinson}.

A few important differences between the scenario described by \citeauthor{levinson16} and the scenario in the present thesis must be noted. First off, \citeauthor{levinson16} is mainly concerned with language only, stating that ``[t]his overlap of comprehension and production raises problems with current psycholinguistic theory'' \citeyearpar[\pnum{9}]{levinson16}. Although he does touch on other modalities in his paper, his main line of argumentation is, if at all, only indirectly concerned with multimodality. In the present scenario, on the other hand, input and output may also be of several non-linguistic modalities (compare the right part of figure \ref{fig:levinson}), where neither the linguistic cues for an upcoming turn end nor the production times for words and clauses apply. Secondly, whereas in \citeauthor{levinson16}'s scenario the second speaker is receiving linguistic input that may contain all sorts of clues and cues as to when the ongoing turn will come to an end, this is not (necessarily) the case in the present scenario. Referring once more to figure \ref{fig:levinson}, one can see that immediately preceding the measured gap there is linguistic input in \citeauthor{levinson16}'s scenario but not in the present scenario. This very last point is, admittedly, a simplification of reality. It is not the case that there cannot be any input, but that one cannot know \emph{if} there is any input (and if so, then of what modality this input is).

There are two possible cases: The delays chosen are either too long or too short. If they are too short, then some but not all of the coincidences will be filtered out. If they are too long, then some real patterns will not be captured but all of the coincidences will be filtered out. It is unlikely, that the delays chosen are exactly right (or that \emph{exactly right} is even a meaningful notion in this context), but for the simple fact that reaction time is always greater than 0~ms I do believe that modelling them is a step in the right direction.

\begin{figure}
	\centering
	\input{../aux/tikzpictures/tikz_levinson.tex}
	\caption{Levinson}
	\label{fig:levinson}
\end{figure}
%Lastly, there is no reason to believe that making use of peak reaction performance is the default case in the present scenario.  % Who cares?

% This turned out to be impractical:
%For intrapersonal rules only, simultaneous start time points of two events are meaningful. In order to capture them, a further adjustment must be made related to coders' imprecision. The data were annotated frame by frame. Given a rate of 25~fpm, the duration of a single frame is 40~ms. Intrapersonal events with a maximum delay of 40~ms are therefore considered to begin simultaneously. The analysis is formalised in appendix \ref{ch:formalisation}.

\section{Results}
\label{sec:miningresults}



































%\subsection{Association Rules}
%In the following, I will first lay out the type of association rule used by \citet{rohlfing18} and then explain how I modified this scheme to better fit the interactional, multimodal nature of the data. The basic sequence is structured as follows:
%\begin{quote}
%	\code{<(A [1,3]),(A,B [3,4]),(A,B,C [4,7]),(C [7,8]),(A,C [8,9]),(A,B,C [9,13])>}
%\end{quote}
%
%In traditional sequential pattern mining, the basic data type---called a sequence---is an ordered set of (unordered) item sets \citep[\pnum{588~ff.}]{han12}. Here, every item set in the sequence has an additional annotation marking the start and end time points between which the item set (that is, one specific occurrence of it) is contained in the data. Figure \ref{fig:idealseq} gives a graphical representation of this example sequence. Rules of the sort \fpmrule{A}{B} must fulfil one of two conditions:
%\begin{enumerate}
%	\item The antecedent's start time point lies before that of the succedent.
%	\item The antecedent's and succedent's start time points are identical, i.e.\ they begin simultaneously.
%\end{enumerate}
%Therefore, in the example sequence one can observe the rules \fpmrule{A}{A,B} but not \fpmrule{B}{A,B}. The following three modifications improve the scheme to better fit the data:
%
%\paragraph{Imprecision of hand-coded data}
%The second condition is problematic given the nature of the data. Every annotation has been hand-coded and with coding by hand comes imprecision. Given the fact that the time points' are precise up to one millisecond, there will in all likelihood not be any two annotations that begin at the exact same point. After examination of the source files (i.e.\ \textsc{elan} files) and consultation with the coders I have decided to allow for a \imprecisiondelay\ delay such that two annotations \(a\) and \(b\) are treated as beginning simultaneously iff their start time points \(s_a\) and \(s_b\) lie no further than 300ms apart (\(|s_a - s_b| < 300ms\)). This delay accounts for the coders' imprecision.
%
%\paragraph{Inter- and intrapersonal rules}
%Given the dyadic nature of the data it is necessary to distinguish between inter- and intrapersonal rules not only in rule evaluation but already in the mining process. Depending on various factors, the average human reaction time to an event lies between XXX and XXXms. %values? source?
%It follows that if both mother and child begin an event at the same time or with a delay below reaction time, then the cooccurrence is pure chance and should not be considered a pattern. Analogous to the maximum delay described in the previous paragraph, interpersonal sequences are only considered with a minimum delay of \reactiontime\ between the time start points.