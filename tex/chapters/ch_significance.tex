% !TEX root = ../scrreprt/ba_scrreprt_master.tex
% @author Marcel Ruland (2018)
%\newcommand{\hnaught}{\textit{H}\textsubscript{\addfontfeature{Numbers=Lining}0}}
%\newcommand{\hone}{\textit{H}\textsubscript{\addfontfeature{Numbers=Lining}1}}
\chapter{\significance}
\label{ch:sig}
\chapterintro{chapter desciption goes here}

\section{The Nature of Significance}\showcomment{Sources for this entire section!}
\label{sec:signat}
In a classic experimental setting, one distinguishes between a control group and an experimental group.
In both groups, all variables are held constant except for a single one\dash the independent variable\dash which is modified in some way \emph{only} in the experimental group.
The object of interest are the potential effects the change of the independent variable in the experimental group may have on another variable, the so-called dependent variable.
This can be done by examining the differences in the dependent variable between the experimental and the control group.
However, simply stating that there is a difference in the dependent variable between the experimental and the control group is meaningless.
Virtually all variables in psychology, linguistics, and their neighbouring fields are to some degree subject to variance.
Therefore, the difference found between the two groups may be pure chance, and hence meaningless.

This is where significance tests come in.
The aim when using significance tests is to find out whether the observed values are a result of chance or if the change made in the experimental group actually does have an influence on the dependent variable.
A few conceptual characteristics must be kept in mind when applying these tests.

Significance tests are based on probability.
They cannot tell us whether an observation is in fact the result of change, but they can tell us how \emph{likely} the observation is to be a result of chance.
The test applied here, explained below\showcomment{Where?}, outputs a classical \pv.
Semantically, the \pv\ expresses the likelihood of observing a value as extreme or more extreme than the actual observed value.
\pv\ between 0 and 1 correspond to likelihoods between 0 and 100~\%.
It is clear that the lower a \pv\ is, the more likely the observation is to represent a real effect.
But it is much less clear how low exactly a \pv\ has to be in order for the effect to be considered real.
Where exactly this arbitrary cutoff, usually denoted by \(\alpha\), is made is pure convention.
In linguistics and psychology, by far the most common cutoff point is \(\alpha\)~=~0.05; i.e.~an effect is considered to be \emph{significant} if its \pv~<~\(\alpha\)~=~0.05.
In other words:
If the likelihood of an observation being the result of chance is less than 5~\%, then by convention the result is considered to be \emph{not} a result of chance.
This concept of having no way of telling whether an observation is the result of chance but knowing the likelihood of it being the result of chance is summarise by \citet[\pnum{291}]{neyman_problem_1933}:

\begin{customquote}
``We are inclined to think that as far as a particular hypothesis is concerned, no test based upon the theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis.
But we may look at the purpose of test from another view-point.
Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behavior with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong.''
\end{customquote}

Knowing what a \pv\ means, it is equally important to know what a \pv\ does not mean.
The likelihood of chance is one important piece of information about an observation, but not the only one.
With any other information about an observation, the \pv\ is of no help whatsoever.
For instance, the \pv\ does not say anything about the size of an effect.
If one was to test the improvement of a new kind of lens to improve the sight of, for example, short-sighted people, one could easily find a \pv\ < 0.05 even though the new lens is of no use in practice.
Because even with the effect being real and not a result of chance, it can still be so small that the tiny improvement in sight cannot be perceived by any human being.
A \pv\ does not help in distinguishing between small and large effects \citep[\cnum{8}]{frost_statistische_2017}.

A \pv\ also does not say anything about the importance or novelty of an effect.
This is especially relevant in the present case where 201 rules have shown significant values for at least one metric.
\citet[\pnum{22}]{han_data_2012} states that ``many patterns that are interesting by objective standards may represent common sense and, therefore, are actually uninteresting.''
Even though the authors are referring to patterns in data mining, a similar line of argumentation holds for statistical significance.
Many significant effects may be significant numerically but ``\citeellipses\ represent common sense and, therefore, are actually uninteresting.''
Having outlined some conceptual key points of statistical significance, the following section explains how statistical significance for a rule's metrics was calculated.




\section{Method}
\label{sec:sigmet}
% why we need significance, general aim
The aim of applying \fpmlower\ to the corpus of mother--infant dyads is to find regularities in early mother--infant interaction.
As explained earlier, the corpus contains 10 sequences all containing whichever regularities are present in the interactions.
The goal of introducing significance is to know whether a rule actually represents a regularity\dash in the sense that mother and infant are intentionally coordinating their behaviour\dash or if a rule is simply a result of chance.
To give an example, if event type \emph{a} is observed at all times and event type \emph{b} only occurs at seldom and random times, then the rule \fpmmediumrule{a}{b} will still have a confidence of 1 even though it does not represent an actual regularity.
If, on the other hand, both \emph{a} and \emph{b} occur rarely in the sequence, but the rule still shows a confidence of >~0.9, then this is a strong indication that \fpmmediumrule{a}{b} represents an actual regularity.
To calculate significance, sequences \emph{not} containing those regularities are needed for comparison.
Alluding to the terminology introduced in the previous\showcomment{Still previous?} section, an experimental group is present (the real sequences) but a control group (regularity-free sequences, henceforth null sequences) is missing.
The goal is to have a \pv\ for every metric for every rule, i.e.~3~\pv\ for every rule (one for its confidence, \noc, and duration respectively).%
\showcomment{Compare methodology of \citet[\pnum{10~f.}]{abu-zhaya_multimodal_2017}, \citet[\pnum{517}]{goldstein_social_2008}, and \citet[\pnum{7}]{hilbrink_early_2015}.}

% how to create a null sequence
The methodological approach taken therefore, is to create randomised null sequences, which then serve as a basis against which the rules of the real sequences can be tested for significance.
A null sequence is created as follows:
Take one of the ten real sequences in the corpus.
For each of the 10 event types (cf.~table \ref{tab:events}) individually, shuffle the events with respect to their start time points, but leave their duration untouched, i.e.~leave the position of their end points untouched \emph{with respect to their start points.}
No events are added or removed.
This process is done for all 10 event types, resulting in a null sequence corresponding to the real sequence its events were taken from.
Figure \ref{fig:null} gives an example hereof.
The top half of the figure is an excerpt of real data taken from a sequence in the corpus.
We see three events of type \mosp, three shorter events of type \mogain, one longer event of type \ingamo, etc.%
\footnote{The excerpt taken did not contain events of all 10 types, empty event types have simply been omitted in the figure.}
The bottom half of the figure shows a corresponding null sequence.
Notice how \mosp\ still contains the same three events of the same length but in a different temporal order.
The same is true for all other event types.
Some event types exclude others, such that they cannot both occur at the same time.
Those events are the three types of gaze for mother and infant respectively.
This was achieved by merging \{\mogain, \mogaob, \mogaaw\} and \{\ingamo, \ingaob, \ingaaw\} respectively into one dimension, then randomising, then separating the event types again.

\begin{figure}
	\centering
	\input{../aux/tikzpictures/tikz_null.tex}
	\label{fig:null}
	\caption[Real and null sequence comparison.]{Comparison of an excerpt of a real sequence (top) and a corresponding null sequence (bottom). Notice how events of each type respectively are shuffled temporally but their number and duration does not change.}
\end{figure}

We now have a null sequence which contains the exact same events as the corresponding real distribution, but shuffled in their temporal order.
The only thing that has changed is the temporal arrangement of the events \emph{with respect to one another.}
If there was some sort of temporal alignment or relationship between two event types, it is now gone.
The following steps are schematised in figure \ref{fig:sig}.
Circles R1 to R10 in the top right of the figure represent real sequences 1 to 10.
In the first step, 100 null sequences are generated for every real sequence (as indicated by the red arrows at the very top of the figure).
The resulting 1000 null sequences are represented by the squares in the top left of the figure.
In the second step, 100 samples of 10 null sequences each are created, represented by the green crossing arrows.
These 100 samples are created by redistributing the null sequences created in the first step.
From each real sequence the 1st null sequence goes into the 1st pack, the 2nd null sequence goes into the 2nd pack, and the \emph{i}-th null sequence goes into the \emph{i}-th pack.
These packs are represented by the lower boxes.
Next, in step three, \fpmlower\ is applied to the 100 samples separately as well as to all ten real sequences together.
Having applied \fpmlower\ to the 100 samples separately, for every rule there are now \(\leq\)~100 observations.
With these observations, in step four a distribution is now formed for every metric of every rule.
Finally, the \pv\ of a given metric of a given rule is the percentage of observations in the null sequences that are greater than or equal to the real observation.
It should be noted, that \emph{significant} implicitly reads as \emph{significantly high} in this thesis.
The test applied is right-tailed, i.e.~only takes significantly high values into account but ignores significantly low ones.
This is not to say that significantly low values are of no interest.
On the contrary, those values most likely contain a lot of valuable information.
It is simply in order to not further increase this thesis' scope and size, that significantly low values are not considered for the time being.

\begin{figure}
	\centering
	\input{../aux/tikzpictures/tikz_significance.tex}
	\label{fig:sig}
	\caption[Introducing significance.]{Schematisation of how the null sequences are created and significance is introduced.}
\end{figure}

This entire process has been repeated twice.
Once with a minimum delay of 289~\ms\ (see subsection \ref{ssec:fpmmetapp}), and a second time with a minimum delay of 850~\ms.
It would have been desirable to repeat the process a third time with no delay at all, which is meaningful for intrapersonal rules.
Unfortunately for practical reasons, this could not be done for the present thesis.

\section{Metrics}
\label{sec:sigmetr}
The following paragraphs will reconsider the three metrics already introduced in section \ref{sec:fpmmetr}.
Instead of their actual values, the focus here will be on semantic interpretation of their \pv\, i.e.~on what it means if a given metric's value is significant.

The most basic interpretation is that of a significantly high \noc.
If the number of times a rule occurs in the real sequence is significantly higher than in the null sequence packs, as explained in the previous section.\showcomment{Still previous?} then this indicates that there is indeed a temporal relationship between antecedent and succedent, i.e.~that the succedent is a reaction to the antecedent.
It does, however, not say anything about the temporal characteristics of the relationship itself.
This is where the other two metrics come in.

A significantly high duration indicates that once a rule has occurred, it is intentionally maintained by the interaction partners rather than dropped at random.
If, for instance, the rule \fpmtextrule{\mogain}{\ingamo} has a significantly high duration (which it does), then this does not say anything about the intentionality of the infant reciprocating the mother's gaze, but it \emph{does} indicate that once the mother's gaze has been reciprocated by the infant, then the interaction partners intentionally keep looking at each other.

Lastly, significantly high confidence indicates that a rule's overlap between antecedent and succedent is intentionally kept high by the interaction partners.
To stick with the example, if the rule \fpmtextrule{\mogain}{\ingamo} has a significantly high confidence (which, again, it does), then this indicates that \emph{if} the infant reciprocates the mother's gaze, then it does so earlier than chance.

Again, as stated at the end of section \ref{sec:fpmmetr}, none of these three metrics make much sense alone.
To evaluate a rule, all three metrics actual values and \pv\ as well as the number of times it has been observed in the null sequence packs must be taken into account.
%\paragraph{Evaluating single rules}
%\paragraph{Evaluating groups of rules}


\section{Results}
\label{sec:sigres}
% overview
When imposing the shorter delay of 289~\ms, a total of 436~rules have been observed in the real sequences.
Of these 436 observed rules, 201 (46.1~\%) have shown significant values in at least one metric; 155 (35.5~\%) in at least two metrics, and 66 (28.7~\%) in all three metrics.
Imposing the longer delay of 850~\ms, a total of 313~rules have been observed, 157 (50.2~\%) of which have shown significant values in at least one metric; 125 (39.9~\%) in at least two metrics, and 56 (44.8~\%) in all three metrics.
With both delays, the metric showing the highest number of significant effects is duration, followed by confidence and \noc.
Even though the process of calculating significance could not be repeated a third time without a delay (see end of section \ref{sec:sigmet}), intrapersonal rules will still be considered.
It must be kept in mind, however, that \emph{all intrapersonal rules may be understating the effects}, falsely sorting out some occurrences as coincidence.
Some example rules will be given in tables with indices in brackets.
If a rule is shown in more than one table (because it fulfils more than one interesting criterion), it will still retain its original index to avoid ambiguity.
%- easier to interpret if fewer event types are in rule

\paragraph{Reciprocating behaviour}
There are ten potential rules indicating direct reciprocating behaviour, such as \fpmtextrule{\mogain}{\ingamo}.
Out of these ten potential rules, six have shown significant values and are shown in table~\ref{tab:reciprocal}.
\fpmtextrule{\mogaaw}{\ingaaw} has also been observed in the real sequence, but only a single time, likely a result of chance.
All of these rules except for \rn{5} have shown both significant confidence and duration values, but no significant \noc.
This indicates that the reciprocal behaviour may not have been established on purpose but once it has been established it is being maintained intentionally.
% joint attention
The only rule showing different significance is \rn{5}, which shows only significant \noc.
This is interesting because gazing at an object is the only behaviour in the list where the interaction partners do not focus their attention on each other but at an object.
The data do not distinguish between different object and therefore it is unclear whether the interaction partners are in fact looking at the same object or at two different ones.
Given the nature of the data\dash a diaper changing routine\dash one can safely assume though, that it was in fact the same object (diaper or toy or item of clothing held by the mother).
In some, but not all of these cases, this may be a case of joint attention, where the interaction partners both jointly focus their attention on an object.
This is more likely to have been the case with a salient object, such as a toy, and less likely with a non-salient object, such as a white diaper or a neutrally coloured item of clothing.\showcomment{Source!}

\begin{table}
\centering
	\begin{tabular}{cl}
		\toprule
		\rn{1} & \fpmtextrule{\ingamo}{\mogain} \\
		\rn{2} & \fpmtextrule{\insm}{\mosm} \\
		\rn{3} & \fpmtextrule{\mogain}{\ingamo} \\
		\rn{4} & \fpmtextrule{\mosm}{\insm} \\
		\cmidrule(lr){1-2}
		\rn{5} & \fpmtextrule{\mogaob}{\ingaob} \\
		\bottomrule
	\end{tabular}
	\caption[Rules showing reciprocal behaviour.]{Rules showing reciprocal behaviour between the interaction partners. \rn{1--4} show significant confidence and duration, \rn{5} shows significant \noc.}
	\label{tab:reciprocal}
\end{table}

\paragraph{High confidence rules}
The two rules with the highest significant confidence are rules \rn{1} and \rn{3} from table \ref{tab:reciprocal}, with confidence values of 0.63 and 0.62 respectively.
Other rules with a significant confidence higher than 0.50 are shown in table \ref{tab:highcon}.
Some have been excluded because they have only been observed a single time.
These mostly interpersonal rules all include gazing at the interaction partner, some also include smiling.
\citet{nomikou_educating_2013} found that mothers use several techniques, such as head movement or facial expressions, to maintain their infant's attention once eye contact has been established.
This is in line with the high-confidence rules found here, where the mutual eye contact is maintained in all rules except \rn{7} and \rn{10}, and smiling is used by the mother in some of them\dash perhaps as a way of keeping up their infant's attention.
Interestingly, none of the rules in table \ref{tab:highcon} show significant \noc.
This may either indicate that establishing mutual gaze is more difficult than maintaining it, or that mutual gaze is not often intentionally established.

\begin{table}
\centering
	\begin{tabularx}{\textwidth}{cX}
		\toprule
		\rn{1} & \fpmtextrule{\ingamo}{\mogain} \\
		\rn{6} & \fpmtextrule{\ingamo, \mosm}{\mogain} \\
		\rn{7} & \fpmtextrule{\mosm}{\mogain} \\
		\rn{8} & \fpmtextrule{\ingamo, \insm, \mosm}{\mogain} \\
		\rn{3} & \fpmtextrule{\mogain}{\ingamo} \\
		\rn{9} & \fpmtextrule{\mogain, \mosm}{\ingamo} \\
		\rn{10} & \fpmtextrule{\mosm}{\ingamo} \\
		\bottomrule
	\end{tabularx}
	\caption{Some rules with significant confidence above 0.50.}
	\label{tab:highcon}
\end{table}

\paragraph{High \noc\ rules}
As explained in the previous section\showcomment{Still previous?}, a rule with a significantly high \noc\ indicates a co-constructed behaviour that is established often, but not necessarily for a long time.
Table \ref{tab:highnoc} shows some rules with high and significant \noc.
\rn{11} and \rn{12} show that significantly often, when the infant gazes at their mother, the mother will respond either verbally or verbally and by gazing back at her infant.
\rn{14} indicates that significantly often in the interaction, the mother initiates her communication by smiling, which is then followed by speaking.
The reverse rule \fpmtextrule{\mosp}{\mosm} is not significant.

\rn{15} occurs 81.6~\% as often as \fpmtextrule{\mogain}{\mosm}, indicating that in 81.6~\% of all cases the mother is successful in capturing her infant's attention by gazing at them and speaking.%
\footnote{Assuming that capturing her infant's attention is in fact the mother's attention in all such cases.}

\rn{12} and \rn{13} are identical except for \mogain, which is in the antecedent in \rn{12} and in the succedent in \rn{13}.
Both rules show significant values in all three metrics.
The confidence is lower in \rn{12} than it is in \rn{13} (0.31 vs 0.41).
This may seem interesting at first but unfortunately carries little semantic value.
Confidence is defined as \(conf(\mathcal{A \rightarrow B}) = \frac{d(\mathcal{A \cup B})}{d(\mathcal{A})}\) (see section \ref{sec:fpmmetr}).
The numerator of the fraction, \(d(\mathcal{A \cup B})\) is identical for both rules:
It is the interval where \{\ingamo, \mogain, \mosm\} is observed.
The denominator is the interval where the antecedent is observed and is therefore different for the two rules.
For rule \rn{12} it contains a single event, whereas for rule \rn{13} it contains two events.
From the fact that the antecedent of \rn{12} is a subset of the antecedent of \rn{13}, it follows that whenever the antecedent of \rn{13} is observed, the antecedent of \rn{12} is also observed.
The opposite does not hold true.
The antecedent of \rn{12} may be observed without observing the antecedent of \rn{13}.
Therefore, the antecedent of \rn{12} may start earlier in time than the antecedent of \rn{13}, which in turn causes the denominator of the fraction to be larger for \rn{12} than for \rn{13}, which then results in a lower confidence value for \rn{12}.
The only information to be drawn from this difference in confidence is that in some instances, when the infant gazes at their mother, the mother started gazing back \emph{before} speaking.

\begin{table}
\centering
	\begin{tabularx}{\textwidth}{>{\addfontfeature{Numbers=Lining,Letters=Uppercase}}cX}
		\toprule
		\rn{11} & \fpmtextrule{\ingamo}{\mosp} \\
		\rn{12} & \fpmtextrule{\ingamo}{\mogain, \mosp} \\
		\rn{13} & \fpmtextrule{\ingamo, \mogain}{\mosp} \\
		\rn{14} & \fpmtextrule{\mosm}{\mosp} \\
		\rn{15} & \fpmtextrule{\mogain}{\ingamo, \mosp} \\
		\bottomrule
	\end{tabularx}
	\caption{Some rules with significant \noc.}
	\label{tab:highnoc}
\end{table}

\paragraph{High duration rules}
When looking for rules with significantly high duration, \rn{1} and \rn{3} are once again at the top of the list.
Together with the high confidence (high in absolute terms and significantly high compared to the null sequences), they indicate that gaze indeed does play a central role in early mother-infant interaction.
The fact that these rules both are not significant for \noc\ may be simply caused by the overall high duration, but this is a tentative thought that needs further investigation before becoming a claim.
Average duration of a rule's occurrences has not been calculated but nevertheless the low number of occurrences together with the highest two overall durations of all rules indicates a high average duration.























































